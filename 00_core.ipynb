{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Cosma Core: Agent Class for Composable Agentic Workflows\"\n",
    "author: \"Charles F. Vardeman II\"\n",
    "description: |\n",
    "  This notebook defines the `Agent` class, which provides the foundation for composable\n",
    "  agentic workflows using Cosma. It includes:\n",
    "  - A flexible `Agent` class for creating tool-using LLM agents.\n",
    "  - Support for composable and extensible AI workflows.\n",
    "  - Integration with cosette, OpenAI API, and Anthropic-recommended patterns.\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    include-in-header:\n",
    "      text: |\n",
    "        <script type=\"application/ld+json\">\n",
    "        {\n",
    "          \"@context\": \"https://doi.org/10.5063/schema/codemeta-2.0\",\n",
    "          \"@type\": \"SoftwareSourceCode\",\n",
    "          \"name\": \"Cosma Core: Agent Class\",\n",
    "          \"description\": \"Defines the `Agent` class, providing the basis for composable agentic workflows in Cosma.\",\n",
    "          \"author\": {\n",
    "            \"@type\": \"Person\",\n",
    "            \"name\": \"Charles F. Vardeman II\",\n",
    "            \"affiliation\": {\n",
    "              \"@type\": \"Organization\",\n",
    "              \"name\": \"Laboratory for Assured AI Application Development (LA3D), Center for Research Computing, University of Notre Dame\"\n",
    "            }\n",
    "          },\n",
    "          \"creator\": {\n",
    "            \"@type\": \"Person\",\n",
    "            \"name\": \"Charles F. Vardeman II\"\n",
    "          },\n",
    "          \"publisher\": {\n",
    "            \"@type\": \"Organization\",\n",
    "            \"name\": \"University of Notre Dame\"\n",
    "          },\n",
    "          \"copyrightHolder\": {\n",
    "            \"@type\": \"Organization\",\n",
    "            \"name\": \"University of Notre Dame\"\n",
    "          },\n",
    "          \"programmingLanguage\": \"Python\",\n",
    "          \"license\": \"https://opensource.org/licenses/MIT\",\n",
    "          \"keywords\": [\"LLM agents\", \"AI\", \"cosette\", \"OpenAI\", \"Anthropic\", \"Agentic workflows\", \"Python\"],\n",
    "          \"codeRepository\": \"https://github.com/your-repository/cosma\",\n",
    "          \"issueTracker\": \"https://github.com/your-repository/cosma/issues\",\n",
    "          \"softwareVersion\": \"0.1.0\",\n",
    "          \"dateCreated\": \"2025-02-15\",\n",
    "          \"dateModified\": \"2025-02-15\",\n",
    "          \"developmentStatus\": \"active\",\n",
    "          \"operatingSystem\": \"Any\",\n",
    "          \"softwareRequirements\": [\"Python >= 3.8\"],\n",
    "          \"funding\": {\n",
    "            \"@type\": \"Organization\",\n",
    "            \"name\": \"Funding Agency Name\"\n",
    "          },\n",
    "          \"isAccessibleForFree\": true,\n",
    "          \"mainEntity\": {\n",
    "            \"@type\": \"Class\",\n",
    "            \"name\": \"Agent\",\n",
    "            \"description\": \"A flexible class for creating tool-using LLM agents and supporting agentic workflows.\"\n",
    "          }\n",
    "        }\n",
    "        </script>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Core Agent functionality for building LLM-powered agents with [cosette](https://github.com/AnswerDotAI/cosette)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "This nbdev notebook was dialog engineered in the [\"Extending Cosette with more agentic functionality\"](https://github.com/LA3D/cosma/blob/main/dialogs/Cosma_Refactor.ipynb). There is an example walkthrough of using the `Agent` class in the [\"Example Agent\"](https://github.com/LA3D/cosma/blob/main/dialogs/Cosma-walkthru.ipynb) notebook.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "from fastcore.basics import patch\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Optional, List, Callable, Dict\n",
    "from cosette import Chat, contents, wrap_latex, models\n",
    "from IPython.display import display, Markdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "## Load keys for testing.\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Tools\n",
    "> Example tools for demonstrating agent functionality\n",
    "\n",
    "Tools must be designed with clear documentation and examples for the LLM to use them effectively. Following Anthropic's guidance:\n",
    "1. Use clear, descriptive parameter names\n",
    "2. Include comprehensive docstrings with examples\n",
    "3. Specify input formats and constraints\n",
    "4. Show example usage patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import math\n",
    "\n",
    "def solve_math(\n",
    "    expression: str  # Mathematical expression as a string (e.g. \"2+2\", \"sqrt(16)\")\n",
    ") -> float:         # Numerical result of the evaluation\n",
    "    \"\"\"Evaluates mathematical expressions using a safe subset of Python's math operations.\n",
    "    \n",
    "    The tool supports these operations:\n",
    "    - Basic arithmetic: +, -, *, /\n",
    "    - Functions: sqrt, pow, sin, cos\n",
    "    - Constants: pi\n",
    "    \n",
    "    Examples:\n",
    "        >>> solve_math(\"2+2\")\n",
    "        4.0\n",
    "        >>> solve_math(\"sqrt(16)\")\n",
    "        4.0\n",
    "        >>> solve_math(\"sin(pi/2)\")\n",
    "        1.0\n",
    "        \n",
    "    Input Format:\n",
    "        - Use standard mathematical notation\n",
    "        - Write functions in lowercase: sqrt(), sin(), cos()\n",
    "        - Use parentheses for function arguments: sqrt(16)\n",
    "        \n",
    "    Safety:\n",
    "        - Only whitelisted math operations are allowed\n",
    "        - No arbitrary Python code execution\n",
    "    \"\"\"\n",
    "    namespace = {\n",
    "        'sqrt': math.sqrt,\n",
    "        'pow': math.pow,\n",
    "        'sin': math.sin,\n",
    "        'cos': math.cos,\n",
    "        'pi': math.pi\n",
    "    }\n",
    "    return eval(expression, {\"__builtins__\": {}}, namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic addition            | 2+2        = 4\n",
      "Square root function      | sqrt(16)   = 4.0\n",
      "Trigonometric with pi constant | sin(pi/2)  = 1.0\n",
      "Power function            | pow(2,3)   = 8.0\n",
      "Cosine of zero            | cos(0)     = 1.0\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# Test basic operations\n",
    "test_cases = [\n",
    "    (\"2+2\", \"Basic addition\"),\n",
    "    (\"sqrt(16)\", \"Square root function\"),\n",
    "    (\"sin(pi/2)\", \"Trigonometric with pi constant\"),\n",
    "    (\"pow(2,3)\", \"Power function\"),\n",
    "    (\"cos(0)\", \"Cosine of zero\")\n",
    "]\n",
    "\n",
    "for expr, desc in test_cases:\n",
    "    result = solve_math(expr)\n",
    "    print(f\"{desc:25} | {expr:10} = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Class\n",
    "> Core class for building LLM-powered agents with tools and memory\n",
    "\n",
    "The Agent class provides a high-level interface for creating LLM agents that can:\n",
    "- Maintain conversation history\n",
    "- Use well-documented tools effectively\n",
    "- Follow specific roles and system prompts\n",
    "- Manage context window automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dataclass\n",
    "class Agent:\n",
    "    \"\"\"An Agent that can perform tasks using an LLM and optional tools.\n",
    "    \n",
    "    The Agent maintains its own conversation state and can use tools to perform\n",
    "    actions. It follows Anthropic's best practices for tool usage and prompting.\n",
    "    \n",
    "    Args:\n",
    "        role: Description of agent's role (e.g. \"math tutor\")\n",
    "        model: LLM model to use (from cosette.models)\n",
    "        tools: Optional list of callable tools with type hints and docstrings\n",
    "        system: Override default system prompt\n",
    "        memory_size: Number of conversation turns to retain\n",
    "    \n",
    "    Example:\n",
    "        ```python\n",
    "        # Create a math tutor agent\n",
    "        math_agent = Agent(\n",
    "            role=\"math tutor\",\n",
    "            model=\"gpt-4o\",\n",
    "            tools=[solve_math],\n",
    "            system=\"You are a helpful math tutor. Show your work and verify with tools.\"\n",
    "        )\n",
    "        \n",
    "        # Use the agent\n",
    "        response = math_agent.run_with_tools(\"What is sqrt(16) + 7?\")\n",
    "        ```\n",
    "    \"\"\"\n",
    "    role: str\n",
    "    model: str\n",
    "    tools: List[Callable] = field(default_factory=list)\n",
    "    system: Optional[str] = None\n",
    "    memory_size: int = 10\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Initialize the agent with model and system prompt.\"\"\"\n",
    "        if self.model not in models: \n",
    "            raise ValueError(f\"Model {self.model} not in available models: {models}\")\n",
    "        self.chat = Chat(self.model, tools=self.tools)\n",
    "        self.chat.sp = self.system or f\"You are a {self.role}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent with model: gpt-4o\n",
      "System prompt: You are a test agent.\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# Test basic agent creation\n",
    "test_agent = Agent(\n",
    "    role=\"test agent\",\n",
    "    model=models[2],  # Use available model\n",
    "    tools=[solve_math]\n",
    ")\n",
    "print(f\"Created agent with model: {test_agent.model}\")\n",
    "print(f\"System prompt: {test_agent.chat.sp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def run_with_tools(self:Agent, prompt:str, max_steps:int=5, **kwargs) -> str:\n",
    "    \"\"\"Execute a conversation turn with automatic tool usage.\n",
    "    \n",
    "    Uses cosette's toolloop to allow the model to:\n",
    "    1. Analyze the prompt\n",
    "    2. Choose appropriate tools\n",
    "    3. Call tools with proper parameters\n",
    "    4. Use results to form response\n",
    "    \n",
    "    Args:\n",
    "        prompt: User's input message\n",
    "        max_steps: Maximum number of tool calls (default: 5)\n",
    "        **kwargs: Additional arguments passed to toolloop\n",
    "    \n",
    "    Returns:\n",
    "        The model's final response after tool usage\n",
    "    \n",
    "    Example:\n",
    "        ```python\n",
    "        agent = Agent(role=\"math tutor\", model=\"gpt-4o\", tools=[solve_math])\n",
    "        response = agent.run_with_tools(\"What is sqrt(16) + sin(pi/2)?\")\n",
    "        ```\n",
    "    \"\"\"\n",
    "    self._prune_history()\n",
    "    response = self.chat.toolloop(prompt, max_steps=max_steps, **kwargs)\n",
    "    return contents(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def show(self:Agent):\n",
    "    \"\"\"Display agent configuration and conversation history.\n",
    "    \n",
    "    Shows:\n",
    "    - Current role and model\n",
    "    - System prompt\n",
    "    - Available tools\n",
    "    - Token usage statistics\n",
    "    - Full conversation history\n",
    "    \"\"\"\n",
    "    config_md = f\"\"\"\n",
    "# Agent Configuration\n",
    "\n",
    "**Role**: {self.role}  \n",
    "**Model**: {self.model}  \n",
    "**System**: {self.chat.sp}  \n",
    "**Memory Size**: {self.memory_size}  \n",
    "**Tools**: {len(self.tools)} - {', '.join(t.__name__ for t in self.tools)}\n",
    "\n",
    "## Token Usage\n",
    "{self.chat.use}\n",
    "\n",
    "## Conversation History\n",
    "{self._format_history()}\n",
    "\"\"\"\n",
    "    display(Markdown(config_md))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def _format_history(self:Agent):\n",
    "    \"\"\"Format conversation history for markdown display.\"\"\"\n",
    "    lines = []\n",
    "    if hasattr(self.chat, 'h') and self.chat.h:\n",
    "        for msg in self.chat.h:\n",
    "            role = msg.role.capitalize()\n",
    "            content = msg.content or \"\"\n",
    "            lines.append(f\"**{role}:** {content}\")\n",
    "    return \"\\n\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def _prune_history(self:Agent):\n",
    "    \"\"\"Maintain conversation history within memory_size limit.\"\"\"\n",
    "    if self.memory_size is None or self.memory_size <= 0: return\n",
    "    if hasattr(self.chat, 'h') and len(self.chat.h) > (self.memory_size + 1):\n",
    "        system_msgs = [msg for msg in self.chat.h if msg.role == 'system']\n",
    "        other_msgs = [msg for msg in self.chat.h if msg.role != 'system'][-self.memory_size:]\n",
    "        self.chat.h = system_msgs + other_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing run_with_tools:\n",
      "Response: The result of \\(\\sqrt{16} + \\sin(\\pi/2)\\) is \\(4 + 1 = 5\\).\n",
      "\n",
      "Testing show:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Agent Configuration\n",
       "\n",
       "**Role**: math tutor  \n",
       "**Model**: gpt-4o  \n",
       "**System**: You are a helpful math tutor. Use tools to verify calculations.  \n",
       "**Memory Size**: 10  \n",
       "**Tools**: 1 - solve_math\n",
       "\n",
       "## Token Usage\n",
       "CompletionUsage(completion_tokens=83, prompt_tokens=545, total_tokens=628, completion_tokens_details=None, prompt_tokens_details=None)\n",
       "\n",
       "## Conversation History\n",
       "**User:** What is sqrt(16) + sin(pi/2)?\n",
       "\n",
       "**Assistant:** \n",
       "\n",
       "**Tool:** 4.0\n",
       "\n",
       "**Tool:** 1.0\n",
       "\n",
       "**Assistant:** The result of \\(\\sqrt{16} + \\sin(\\pi/2)\\) is \\(4 + 1 = 5\\).\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | hide\n",
    "# Test the methods\n",
    "test_agent = Agent(\n",
    "    role=\"math tutor\",\n",
    "    model=models[2],\n",
    "    tools=[solve_math],\n",
    "    system=\"You are a helpful math tutor. Use tools to verify calculations.\"\n",
    ")\n",
    "\n",
    "# Test run_with_tools\n",
    "print(\"Testing run_with_tools:\")\n",
    "response = test_agent.run_with_tools(\"What is sqrt(16) + sin(pi/2)?\")\n",
    "print(f\"Response: {response}\\n\")\n",
    "\n",
    "# Show agent state\n",
    "print(\"Testing show:\")\n",
    "test_agent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
