{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Cosma from GitHub\n",
    "# !pip install --force-reinstall git+https://github.com/la3d/cosma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosma.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrole\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtools\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfactory\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msystem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmemory_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "An Agent that can perform tasks using an LLM and optional tools.\n",
      "\n",
      "The Agent maintains its own conversation state and can use tools to perform\n",
      "actions. It follows Anthropic's best practices for tool usage and prompting.\n",
      "\n",
      "Args:\n",
      "    role: Description of agent's role (e.g. \"math tutor\")\n",
      "    model: LLM model to use (from cosette.models)\n",
      "    tools: Optional list of callable tools with type hints and docstrings\n",
      "    system: Override default system prompt\n",
      "    memory_size: Number of conversation turns to retain\n",
      "\n",
      "Example:\n",
      "    ```python\n",
      "    # Create a math tutor agent\n",
      "    math_agent = Agent(\n",
      "        role=\"math tutor\",\n",
      "        model=\"gpt-4o\",\n",
      "        tools=[solve_math],\n",
      "        system=\"You are a helpful math tutor. Show your work and verify with tools.\"\n",
      "    )\n",
      "    \n",
      "    # Use the agent\n",
      "    response = math_agent.run_with_tools(\"What is sqrt(16) + 7?\")\n",
      "    ```\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"An Agent that can perform tasks using an LLM and optional tools.\u001b[0m\n",
      "\u001b[0;34m    \u001b[0m\n",
      "\u001b[0;34m    The Agent maintains its own conversation state and can use tools to perform\u001b[0m\n",
      "\u001b[0;34m    actions. It follows Anthropic's best practices for tool usage and prompting.\u001b[0m\n",
      "\u001b[0;34m    \u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m        role: Description of agent's role (e.g. \"math tutor\")\u001b[0m\n",
      "\u001b[0;34m        model: LLM model to use (from cosette.models)\u001b[0m\n",
      "\u001b[0;34m        tools: Optional list of callable tools with type hints and docstrings\u001b[0m\n",
      "\u001b[0;34m        system: Override default system prompt\u001b[0m\n",
      "\u001b[0;34m        memory_size: Number of conversation turns to retain\u001b[0m\n",
      "\u001b[0;34m    \u001b[0m\n",
      "\u001b[0;34m    Example:\u001b[0m\n",
      "\u001b[0;34m        ```python\u001b[0m\n",
      "\u001b[0;34m        # Create a math tutor agent\u001b[0m\n",
      "\u001b[0;34m        math_agent = Agent(\u001b[0m\n",
      "\u001b[0;34m            role=\"math tutor\",\u001b[0m\n",
      "\u001b[0;34m            model=\"gpt-4o\",\u001b[0m\n",
      "\u001b[0;34m            tools=[solve_math],\u001b[0m\n",
      "\u001b[0;34m            system=\"You are a helpful math tutor. Show your work and verify with tools.\"\u001b[0m\n",
      "\u001b[0;34m        )\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m        # Use the agent\u001b[0m\n",
      "\u001b[0;34m        response = math_agent.run_with_tools(\"What is sqrt(16) + 7?\")\u001b[0m\n",
      "\u001b[0;34m        ```\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrole\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtools\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msystem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmemory_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Initialize the agent with model and system prompt.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model {self.model} not in available models: {models}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mf\"You are a {self.role}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.11/site-packages/cosma/core.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "Agent??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_with_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcosma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprompt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Execute a conversation turn with automatic tool usage.\n",
      "\n",
      "Uses cosette's toolloop to allow the model to:\n",
      "1. Analyze the prompt\n",
      "2. Choose appropriate tools\n",
      "3. Call tools with proper parameters\n",
      "4. Use results to form response\n",
      "\n",
      "Args:\n",
      "    prompt: User's input message\n",
      "    max_steps: Maximum number of tool calls (default: 5)\n",
      "    **kwargs: Additional arguments passed to toolloop\n",
      "\n",
      "Returns:\n",
      "    The model's final response after tool usage\n",
      "\n",
      "Example:\n",
      "    ```python\n",
      "    agent = Agent(role=\"math tutor\", model=\"gpt-4o\", tools=[solve_math])\n",
      "    response = agent.run_with_tools(\"What is sqrt(16) + sin(pi/2)?\")\n",
      "    ```\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.11/site-packages/cosma/core.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "Agent.run_with_tools?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcosma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Display agent configuration and conversation history.\n",
      "\n",
      "Shows:\n",
      "- Current role and model\n",
      "- System prompt\n",
      "- Available tools\n",
      "- Token usage statistics\n",
      "- Full conversation history\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.11/site-packages/cosma/core.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "Agent.show?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcosma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0m_format_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Format conversation history for markdown display.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**{role}:** {content}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.11/site-packages/cosma/core.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "Agent._format_history??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcosma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0m_prune_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Maintain conversation history within memory_size limit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msystem_msgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'system'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mother_msgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'system'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem_msgs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mother_msgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.11/site-packages/cosma/core.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "Agent._prune_history??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Hi solveit! I am Chuck, and I am working with you today! I'm know basic Python, LLM prompt programming and engineering, and I enjoy learning new things. When writing code for me, please follow fast.ai coding style: avoid comments; place single line if/loop/etc constructs on the same line; use concise variable names where appropriate. Follow the style you will see in my messages, as we work on this dialogue together. Please follow the Anthropic prompt engineering recommendations and utilize patterns from the Anthropic Agent Guidance. I am interested in extending cosette and cosma for building agentic workflows and approaches in a Solve It environment. We want to do this using the Fast.ai/solveit approach using literate exploratory programming. Are you ready?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Hi Chuck! I'd be happy to help you explore agentic workflows with cosma and solveit using a literate programming approach. \n",
    "\n",
    "Before we dive in, could you tell me what specific aspects of agent workflows you're most interested in exploring? For example:\n",
    "- Building custom tools for agents\n",
    "- Managing conversation state\n",
    "- Implementing specific agent patterns\n",
    "- Something else?\n",
    "\n",
    "This will help me tailor our exploration to your interests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Can you tell me about cosma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Based on the code we've seen, cosma appears to be a framework for building AI agents with a focus on simplicity and best practices. The core component is the `Agent` class, which has these key features:\n",
    "\n",
    "1. Simple initialization with:\n",
    "   - A role (e.g. \"math tutor\")\n",
    "   - A model choice\n",
    "   - Optional tools (Python functions)\n",
    "   - Optional system prompt\n",
    "   - Memory management\n",
    "\n",
    "2. Key capabilities:\n",
    "   - Running conversations with tool usage\n",
    "   - Managing conversation history\n",
    "   - Automatic tool selection and execution\n",
    "   - Built-in memory pruning\n",
    "\n",
    "Would you like me to explain any of these aspects in more detail, or would you like to see how to create a basic agent to explore its functionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Ok I've given you the core classes. What is an Agent and can you show me how to build one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "From the provided code and Anthropic's guidance, an Agent is an LLM-powered system that can:\n",
    "1. Maintain its own conversation state\n",
    "2. Use tools to perform actions\n",
    "3. Follow a defined role\n",
    "4. Make decisions about how to accomplish tasks\n",
    "\n",
    "Would you like to create a simple agent together? I can guide you through building one step by step, starting with a basic example. We can use the `Agent` class from cosma to do this.\n",
    "\n",
    "Before we write any code, what kind of agent would you like to create? For instance, we could build:\n",
    "- A math helper using the built-in `solve_math` tool\n",
    "- A custom agent with your own tools\n",
    "- A specialized agent for a specific task\n",
    "\n",
    "Let me know which interests you and we can start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "I'm not sure, can you help me? I really don't know much about or understand agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Let me break this down in a simpler way. Think of an agent as a smart assistant that can:\n",
    "\n",
    "1. Have a conversation with you\n",
    "2. Use special tools to help with tasks\n",
    "3. Remember what you've discussed (within limits)\n",
    "4. Follow a specific role (like being a tutor or a coding helper)\n",
    "\n",
    "For example, imagine you have a calculator app. A regular calculator just does what you tell it. But an agent with a calculator tool would:\n",
    "- Understand your questions in plain English\n",
    "- Figure out which calculations to do\n",
    "- Use the calculator tool when needed\n",
    "- Explain the results to you\n",
    "\n",
    "Would it help if we started by building a very simple agent that can do basic math? We could use that as a way to understand how agents work, and then build something more complex once you're comfortable with the basics.\n",
    "\n",
    "Would you like to try that approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Yes! I would like to try that approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Great! Let's start by creating a simple math agent. \n",
    "\n",
    "First, we'll need a basic tool for our agent to use. I can show you how to create one, or we can use the built-in `solve_math` tool that comes with cosma. Which would you prefer?\n",
    "\n",
    "Also, do you want me to guide you through writing the code, or would you like me to provide the code for you to try out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Could you provide me with the code? Remember when you are building the code, it is not just for me but for the Agent so make sure every step is understandable to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "I'll provide code for a simple math agent, with clear documentation that both you and the LLM can understand. Here's the first step - creating our math tool:\n",
    "\n",
    "```python\n",
    "def solve_math(\n",
    "    expression: str  # A mathematical expression as a string (e.g. \"2+2\", \"sqrt(16)\")\n",
    ") -> float:         # Returns the numerical result of evaluating the expression\n",
    "    \"\"\"Evaluates basic mathematical expressions safely.\n",
    "    \n",
    "    The tool supports:\n",
    "    - Basic arithmetic: +, -, *, /\n",
    "    - Functions: sqrt, pow, sin, cos\n",
    "    - Constants: pi\n",
    "    \n",
    "    Examples:\n",
    "        >>> solve_math(\"2+2\")\n",
    "        4.0\n",
    "        >>> solve_math(\"sqrt(16)\")\n",
    "        4.0\n",
    "    \n",
    "    Input Format:\n",
    "    - Use standard mathematical notation\n",
    "    - Write functions in lowercase: sqrt(), sin(), cos()\n",
    "    - Use parentheses for function arguments\n",
    "    \"\"\"\n",
    "    import math\n",
    "    return float(eval(expression, {\"__builtins__\": None}, {k:v for k,v in math.__dict__.items() if not k.startswith(\"_\")}))\n",
    "```\n",
    "\n",
    "Would you like me to explain this code before we move on to creating the agent that will use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Yes. Explain to me what this code does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Let me break down this math tool:\n",
    "\n",
    "1. The function definition:\n",
    "   - Takes a string input like \"2+2\" or \"sqrt(16)\"\n",
    "   - Returns a float (decimal number) as the result\n",
    "   - Has type hints (str -> float) which helps the LLM understand the expected inputs/outputs\n",
    "\n",
    "2. The docstring (\"\"\") is crucial because:\n",
    "   - Tells both you and the LLM what operations are allowed\n",
    "   - Provides clear examples of usage\n",
    "   - Specifies the input format requirements\n",
    "   - This documentation helps the LLM know exactly how to use the tool\n",
    "\n",
    "3. The actual code:\n",
    "   ```python\n",
    "   import math\n",
    "   return float(eval(expression, {\"__builtins__\": None}, {k:v for k,v in math.__dict__.items() if not k.startswith(\"_\")}))\n",
    "   ```\n",
    "   This line does several important things for safety:\n",
    "   - Only allows math functions (no arbitrary Python code)\n",
    "   - Removes access to built-in Python functions\n",
    "   - Only includes math functions that don't start with \"_\"\n",
    "   - Converts the result to a float\n",
    "\n",
    "Would you like me to show you how to test this function before we create the agent that will use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Yes. Let's test this function to make sure it does what we think it should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "I'll show you some test cases. Try running this code:\n",
    "\n",
    "```python\n",
    "# Test basic arithmetic\n",
    "print(solve_math(\"2 + 2\"))\n",
    "print(solve_math(\"10 - 3\"))\n",
    "print(solve_math(\"4 * 5\"))\n",
    "print(solve_math(\"20 / 4\"))\n",
    "\n",
    "# Test math functions\n",
    "print(solve_math(\"sqrt(16)\"))\n",
    "print(solve_math(\"sin(pi/2)\"))\n",
    "```\n",
    "\n",
    "Let's run these tests first and see what happens. After you run them, we can try:\n",
    "1. Testing some more complex expressions\n",
    "2. Testing what happens with invalid inputs\n",
    "3. Testing the limits of what math functions are available\n",
    "\n",
    "Which would you like to try next after we see the results of these basic tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "7\n",
      "20\n",
      "5.0\n",
      "4.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Test basic arithmetic\n",
    "print(solve_math(\"2 + 2\"))\n",
    "print(solve_math(\"10 - 3\"))\n",
    "print(solve_math(\"4 * 5\"))\n",
    "print(solve_math(\"20 / 4\"))\n",
    "\n",
    "# Test math functions\n",
    "print(solve_math(\"sqrt(16)\"))\n",
    "print(solve_math(\"sin(pi/2)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Ok. This seems to work! What next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Great! Now that we've confirmed our math tool works, we can create an agent that will use it. Let me show you how to create a basic math agent using cosma.\n",
    "\n",
    "Would you like me to provide the code for:\n",
    "1. A simple math agent that can understand and solve basic math problems\n",
    "2. Or would you prefer we first test some more complex cases with our `solve_math` function to really understand its capabilities?\n",
    "\n",
    "Which would you prefer to explore first?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Let's move on to the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "I'll show you how to create a basic math agent. Here's the code to create one:\n",
    "\n",
    "```python\n",
    "from cosma.core import Agent\n",
    "\n",
    "math_agent = Agent(\n",
    "    role=\"math tutor\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[solve_math],\n",
    "    system=\"You are a helpful math tutor who can solve mathematical expressions. Always verify calculations using the solve_math tool.\"\n",
    ")\n",
    "```\n",
    "\n",
    "This creates an agent that:\n",
    "- Acts as a math tutor\n",
    "- Uses GPT-4\n",
    "- Has access to our solve_math tool\n",
    "- Is instructed to verify calculations\n",
    "\n",
    "Would you like me to explain each part of this setup, or should we try running it and testing how it works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosma.core import Agent\n",
    "\n",
    "math_agent = Agent(\n",
    "    role=\"math tutor\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[solve_math],\n",
    "    system=\"You are a helpful math tutor who can solve mathematical expressions. Always verify calculations using the solve_math tool.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "What next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Now let's test our math agent! We can use the `run_with_tools` method to ask it to solve a math problem. \n",
    "\n",
    "Would you like to try:\n",
    "1. A simple arithmetic question\n",
    "2. A more complex mathematical expression\n",
    "3. Or ask it to explain a mathematical concept?\n",
    "\n",
    "Pick one and I'll show you how to interact with the agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Let's try a simple arithmetic question and then maybe try the mathematical concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Great choice! Let's start with a simple arithmetic question. Here's how to ask the agent:\n",
    "\n",
    "```python\n",
    "response = math_agent.run_with_tools(\"What is 15 times 7 plus 22?\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "Try running this and let's see how the agent responds. After we see its response, we can:\n",
    "1. Look at how it used the tools\n",
    "2. Ask it to explain its reasoning\n",
    "3. Move on to asking about a mathematical concept\n",
    "\n",
    "Which would you like to do after we see the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of \\( 15 \\times 7 + 22 \\) is 127.\n"
     ]
    }
   ],
   "source": [
    "response = math_agent.run_with_tools(\"What is 15 times 7 plus 22?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "I think this worked? Is there a way I can see what is happening under the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Yes! We can see what's happening under the hood in a couple of ways:\n",
    "\n",
    "1. We can use the `show()` method to see the full conversation history and tool usage:\n",
    "```python\n",
    "math_agent.show()\n",
    "```\n",
    "\n",
    "2. Or we can add `trace_func=print` to see each step as it happens:\n",
    "```python\n",
    "response = math_agent.run_with_tools(\"What is 25 divided by 5?\", trace_func=print)\n",
    "```\n",
    "\n",
    "Would you like to try one of these approaches to see how the agent is working internally?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Let's start with the show method first and then the trace?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Good idea! Let's look at what's happened so far using `show()`:\n",
    "\n",
    "```python\n",
    "math_agent.show()\n",
    "```\n",
    "\n",
    "After we see this output, we can then try a new calculation with the trace function to watch it work step by step. Would you like to run this first and then move on to the trace example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Agent Configuration\n",
       "\n",
       "**Role**: math tutor  \n",
       "**Model**: gpt-4o  \n",
       "**System**: You are a helpful math tutor who can solve mathematical expressions. Always verify calculations using the solve_math tool.  \n",
       "**Memory Size**: 10  \n",
       "**Tools**: 1 - solve_math\n",
       "\n",
       "## Token Usage\n",
       "CompletionUsage(completion_tokens=40, prompt_tokens=515, total_tokens=555, completion_tokens_details=None, prompt_tokens_details=None)\n",
       "\n",
       "## Conversation History\n",
       "**User:** What is 15 times 7 plus 22?\n",
       "\n",
       "**Assistant:** \n",
       "\n",
       "**Tool:** 127\n",
       "\n",
       "**Assistant:** The result of \\( 15 \\times 7 + 22 \\) is 127.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "math_agent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "What am I looking at here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Let me break down what we're seeing in the `show()` output:\n",
    "\n",
    "1. Agent Configuration:\n",
    "   - Role: \"math tutor\"\n",
    "   - Model: \"gpt-4o\"\n",
    "   - System prompt: The instructions we gave the agent\n",
    "   - Memory Size: 10 (it remembers up to 10 conversation turns)\n",
    "   - Tools: Our solve_math function\n",
    "\n",
    "2. Token Usage:\n",
    "   - Shows how many tokens were used in the conversation\n",
    "   - Prompt tokens: 515 (input)\n",
    "   - Completion tokens: 40 (output)\n",
    "   - Total: 555\n",
    "\n",
    "3. Conversation History:\n",
    "   - Shows our question: \"What is 15 times 7 plus 22?\"\n",
    "   - Shows the tool being used (returning 127)\n",
    "   - Shows the final response with formatted math\n",
    "\n",
    "Would you like to try the trace function now to see the step-by-step process as it happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Yes. I would like to try trace!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Great! Let's use the trace function to watch the agent solve a problem step by step. Here's the code:\n",
    "\n",
    "```python\n",
    "response = math_agent.run_with_tools(\"What is the square root of 144 plus 10?\", trace_func=print)\n",
    "print(\"\\nFinal response:\", response)\n",
    "```\n",
    "\n",
    "This will show us each step of the agent's thought process and tool usage as it happens. Run this and we can observe how the agent:\n",
    "1. Interprets the question\n",
    "2. Decides what calculations to make\n",
    "3. Uses the tools\n",
    "4. Forms its final response\n",
    "\n",
    "Would you like to run this and then analyze what we see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-B1HbK1DYLgfQtcXQTYZUJet12FstY', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_EqSTfs9AO7j1fDGxpSjszybg', function=Function(arguments='{\"expression\":\"sqrt(144)+10\"}', name='solve_math'), type='function')]))], created=1739645686, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_523b9b6e5f', usage=In: 310; Out: 19; Total: 329)\n",
      "ChatCompletion(id='chatcmpl-B1HbLEi4nHjLWGZW0aQctjrOmvHsC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The result of \\\\(\\\\sqrt{144} + 10\\\\) is 22.0.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1739645687, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_523b9b6e5f', usage=In: 339; Out: 22; Total: 361)\n",
      "\n",
      "Final response: The result of \\(\\sqrt{144} + 10\\) is 22.0.\n"
     ]
    }
   ],
   "source": [
    "response = math_agent.run_with_tools(\"What is the square root of 144 plus 10?\", trace_func=print)\n",
    "print(\"\\nFinal response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "What am I looking at here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Let me break down what we're seeing in the trace output. The agent went through two main steps:\n",
    "\n",
    "1. First ChatCompletion:\n",
    "   - The agent decided to use the solve_math tool\n",
    "   - It formatted the expression as \"sqrt(144)+10\"\n",
    "   - This shows the agent understood it needed to:\n",
    "     * Calculate square root of 144\n",
    "     * Add 10 to the result\n",
    "\n",
    "2. Second ChatCompletion:\n",
    "   - After getting the result (22.0)\n",
    "   - It formatted a nice response with LaTeX math notation\n",
    "   - Gave us the final answer: \"The result of \\(\\sqrt{144} + 10\\) is 22.0.\"\n",
    "\n",
    "The trace_func lets us see this step-by-step process that usually happens behind the scenes. Would you like to:\n",
    "1. Try another example with a more complex calculation?\n",
    "2. Explore how to modify the agent's behavior?\n",
    "3. Learn how to use different tools with the agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "I sort of think I'm getting the idea. Can you come up with a different example then our calculator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Of course! Let's create a different type of agent that could be more interesting. Here are a few ideas:\n",
    "\n",
    "1. A writing assistant that can help with text analysis and formatting\n",
    "2. A simple research agent that can organize information into categories\n",
    "3. A coding helper that can explain and format Python code\n",
    "\n",
    "Each of these would use different tools and demonstrate different agent capabilities. Which one interests you most? We can build it together and see how it works differently from our math agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "The codeing helper sounds interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Great choice! For a coding helper agent, we'll want to create a tool that can handle Python code formatting and analysis. Let's build this step by step.\n",
    "\n",
    "First, shall we create a simple tool that can:\n",
    "1. Format Python code (make it look nice and consistent)\n",
    "2. Run Python code safely and return the output\n",
    "3. Provide basic code analysis\n",
    "\n",
    "Would you like me to show you how to create this tool first? Then we can use it to build our coding helper agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Yes. Let's create a tool first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "I'll show you how to create a code formatting tool. Here's the code with clear documentation for both you and the LLM to understand:\n",
    "\n",
    "```python\n",
    "def format_code(\n",
    "    code: str,  # Python code as a string to be formatted\n",
    "    action: str = \"format\"  # Action to perform: \"format\", \"analyze\", or \"run\"\n",
    ") -> str:  # Returns formatted code or analysis results\n",
    "    \"\"\"A tool for formatting, analyzing, and safely running Python code.\n",
    "    \n",
    "    Actions:\n",
    "    - \"format\": Formats the code using proper indentation and spacing\n",
    "    - \"analyze\": Provides basic code structure analysis\n",
    "    - \"run\": Safely executes code and returns the output\n",
    "    \n",
    "    Examples:\n",
    "        >>> format_code(\"def hello(): print('hi')\", \"format\")\n",
    "        \"def hello():\\n    print('hi')\"\n",
    "        >>> format_code(\"x=1+2\", \"analyze\")\n",
    "        \"Simple assignment with arithmetic operation\"\n",
    "    \n",
    "    Safety:\n",
    "    - Only basic Python operations allowed\n",
    "    - No file or system operations\n",
    "    - No network access\n",
    "    \"\"\"\n",
    "    import black\n",
    "    from io import StringIO\n",
    "    import sys\n",
    "    \n",
    "    if action == \"format\":\n",
    "        try: return black.format_str(code, mode=black.Mode())\n",
    "        except: return \"Error: Could not format code\"\n",
    "    \n",
    "    return \"Action not supported yet\"\n",
    "```\n",
    "\n",
    "Would you like me to explain how this tool works before we create an agent to use it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_code(\n",
    "    code: str,  # Python code as a string to be formatted\n",
    "    action: str = \"format\"  # Action to perform: \"format\", \"analyze\", or \"run\"\n",
    ") -> str:  # Returns formatted code or analysis results\n",
    "    \"\"\"A tool for formatting, analyzing, and safely running Python code.\n",
    "    \n",
    "    Actions:\n",
    "    - \"format\": Formats the code using proper indentation and spacing\n",
    "    - \"analyze\": Provides basic code structure analysis\n",
    "    - \"run\": Safely executes code and returns the output\n",
    "    \n",
    "    Examples:\n",
    "        >>> format_code(\"def hello(): print('hi')\", \"format\")\n",
    "        \"def hello():\\n    print('hi')\"\n",
    "        >>> format_code(\"x=1+2\", \"analyze\")\n",
    "        \"Simple assignment with arithmetic operation\"\n",
    "    \n",
    "    Safety:\n",
    "    - Only basic Python operations allowed\n",
    "    - No file or system operations\n",
    "    - No network access\n",
    "    \"\"\"\n",
    "    import black\n",
    "    from io import StringIO\n",
    "    import sys\n",
    "    \n",
    "    if action == \"format\":\n",
    "        try: return black.format_str(code, mode=black.Mode())\n",
    "        except: return \"Error: Could not format code\"\n",
    "    \n",
    "    return \"Action not supported yet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Explain how this tool works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Let me break down how this tool works:\n",
    "\n",
    "1. Function Parameters:\n",
    "   - `code`: Takes Python code as a string input\n",
    "   - `action`: Tells the tool what to do (format/analyze/run)\n",
    "   - Returns a string with the result\n",
    "\n",
    "2. Documentation:\n",
    "   - Clear description of what the tool does\n",
    "   - Lists available actions\n",
    "   - Shows examples of usage\n",
    "   - Specifies safety limitations\n",
    "   - This helps the LLM understand how to use the tool correctly\n",
    "\n",
    "3. The Code:\n",
    "   - Uses the `black` library (Python's code formatter)\n",
    "   - Currently only implements the \"format\" action\n",
    "   - Has error handling (try/except)\n",
    "   - Returns an error message if formatting fails\n",
    "\n",
    "Would you like to:\n",
    "1. Test this tool with some example code?\n",
    "2. Add more functionality (like the analyze or run features)?\n",
    "3. Create an agent that uses this tool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Let's test this tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Great! Let's test our format_code tool with a few examples. Here's some code to try:\n",
    "\n",
    "```python\n",
    "# Test with messy code formatting\n",
    "messy_code = \"def hello(name):    print('Hello,'+name);return name\"\n",
    "print(\"Original code:\")\n",
    "print(messy_code)\n",
    "print(\"\\nFormatted code:\")\n",
    "print(format_code(messy_code))\n",
    "\n",
    "# Test with a more complex example\n",
    "complex_code = \"\"\"def calculate(x,y): \n",
    "    result=x+y;print('Result:',result)\n",
    "    return     result\"\"\"\n",
    "print(\"\\nOriginal complex code:\")\n",
    "print(complex_code)\n",
    "print(\"\\nFormatted complex code:\")\n",
    "print(format_code(complex_code))\n",
    "```\n",
    "\n",
    "Let's run this and see how our tool handles formatting these examples. After we see the results, we can:\n",
    "1. Try more complex examples\n",
    "2. Test error handling\n",
    "3. Add new functionality\n",
    "\n",
    "Which would you like to explore next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original code:\n",
      "def hello(name):    print('Hello,'+name);return name\n",
      "\n",
      "Formatted code:\n",
      "def hello(name):\n",
      "    print(\"Hello,\" + name)\n",
      "    return name\n",
      "\n",
      "\n",
      "Original complex code:\n",
      "def calculate(x,y): \n",
      "    result=x+y;print('Result:',result)\n",
      "    return     result\n",
      "\n",
      "Formatted complex code:\n",
      "def calculate(x, y):\n",
      "    result = x + y\n",
      "    print(\"Result:\", result)\n",
      "    return result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with messy code formatting\n",
    "messy_code = \"def hello(name):    print('Hello,'+name);return name\"\n",
    "print(\"Original code:\")\n",
    "print(messy_code)\n",
    "print(\"\\nFormatted code:\")\n",
    "print(format_code(messy_code))\n",
    "\n",
    "# Test with a more complex example\n",
    "complex_code = \"\"\"def calculate(x,y): \n",
    "    result=x+y;print('Result:',result)\n",
    "    return     result\"\"\"\n",
    "print(\"\\nOriginal complex code:\")\n",
    "print(complex_code)\n",
    "print(\"\\nFormatted complex code:\")\n",
    "print(format_code(complex_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Ok. I think our tool works. Now what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Now that we've confirmed our tool works, we can create a coding helper agent that uses it! We have two options:\n",
    "\n",
    "1. Create a basic coding assistant that just formats code\n",
    "2. Enhance our tool first to add the \"analyze\" and \"run\" features, then create a more capable agent\n",
    "\n",
    "Which would you prefer? We can start simple and add features later, or build out more functionality now. What would be most helpful for you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Let's start simple and then build capability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Great approach! Let's create a basic coding assistant first. Here's how we can create an agent that helps with code formatting:\n",
    "\n",
    "```python\n",
    "code_agent = Agent(\n",
    "    role=\"Python coding assistant\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[format_code],\n",
    "    system=\"You are a helpful Python coding assistant. When you see Python code, use the format_code tool to improve its formatting. Explain the formatting changes you make.\"\n",
    ")\n",
    "```\n",
    "\n",
    "Would you like to test this basic agent with some messy code and see how it helps? After that, we can discuss which capability to add next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_agent = Agent(\n",
    "    role=\"Python coding assistant\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[format_code],\n",
    "    system=\"You are a helpful Python coding assistant. When you see Python code, use the format_code tool to improve its formatting. Explain the formatting changes you make.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Now what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Let's test our coding assistant with a messy piece of code. We can use the `run_with_tools` method like we did with our math agent, but this time for code formatting. Here's a test we can try:\n",
    "\n",
    "```python\n",
    "messy_code = \"\"\"def fibonacci(n):\n",
    "  if n<=1:return n\n",
    "  else:return fibonacci(n-1)+fibonacci(n-2)\n",
    "  \"\"\"\n",
    "\n",
    "response = code_agent.run_with_tools(f\"Can you help format this code properly?\\n{messy_code}\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "Would you like to:\n",
    "1. Run this test and see how the agent helps?\n",
    "2. Try a different piece of code?\n",
    "3. See the step-by-step process using trace_func?\n",
    "\n",
    "Which would you prefer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the properly formatted code:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    if n <= 1:\n",
      "        return n\n",
      "    else:\n",
      "        return fibonacci(n - 1) + fibonacci(n - 2)\n",
      "```\n",
      "\n",
      "### Changes Made:\n",
      "1. **Indentation**: Enhanced readability by ensuring consistent 4-space indentation for the if-else block.\n",
      "2. **Spacing Around Operators and Conditionals**: Added spaces around the `<=` operator to make it clearer.\n",
      "3. **Line Breaks**: Placed separate lines for the `return` statements to improve readability.\n",
      "\n",
      "These changes adhere to the common Python style guide (PEP 8), making the code more readable and maintainable.\n"
     ]
    }
   ],
   "source": [
    "messy_code = \"\"\"def fibonacci(n):\n",
    "  if n<=1:return n\n",
    "  else:return fibonacci(n-1)+fibonacci(n-2)\n",
    "  \"\"\"\n",
    "\n",
    "response = code_agent.run_with_tools(f\"Can you help format this code properly?\\n{messy_code}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Did this work as we expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Yes, it worked quite well! Our agent:\n",
    "1. Took the messy code\n",
    "2. Used the format_code tool to clean it up\n",
    "3. Provided a clear explanation of the changes it made\n",
    "4. Even referenced PEP 8 (Python's style guide)\n",
    "\n",
    "Would you like to:\n",
    "1. Add the \"analyze\" feature to our tool so the agent can explain what the code does?\n",
    "2. Try formatting a more complex piece of code?\n",
    "3. Add the \"run\" feature so we can test if the code works?\n",
    "\n",
    "Which next step interests you most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "How can we be sure that this worked?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Good question! We can verify our agent's work in several ways:\n",
    "\n",
    "1. We can use the `show()` method to see the full interaction:\n",
    "```python\n",
    "code_agent.show()\n",
    "```\n",
    "\n",
    "2. We can use trace_func to see the step-by-step process:\n",
    "```python\n",
    "response = code_agent.run_with_tools(f\"Can you help format this code properly?\\n{messy_code}\", trace_func=print)\n",
    "```\n",
    "\n",
    "3. We can try running both versions of the code (original and formatted) to make sure they produce the same results.\n",
    "\n",
    "Would you like to try any of these verification methods? Which one interests you most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-B1Hn2B27STteuMZnSZ6F0q1xGZ1KM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is the properly formatted code:\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 1:\\n        return n\\n    else:\\n        return fibonacci(n - 1) + fibonacci(n - 2)\\n```\\n\\n### Changes Made:\\n1. **Indentation**: Enhanced readability by ensuring consistent 4-space indentation for the if-else block.\\n2. **Spacing Around Operators and Conditionals**: Added spaces around the `<=` operator to make it clearer.\\n3. **Line Breaks**: Placed separate lines for the `return` statements to improve readability.\\n\\nThese changes adhere to the common Python style guide (PEP 8), making the code more readable and maintainable.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1739646412, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_523b9b6e5f', usage=In: 542; Out: 144; Total: 686)\n"
     ]
    }
   ],
   "source": [
    "response = code_agent.run_with_tools(f\"Can you help format this code properly?\\n{messy_code}\", trace_func=print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the properly formatted code:\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 1:\\n        return n\\n    else:\\n        return fibonacci(n - 1) + fibonacci(n - 2)\\n```\\n\\n### Changes Made:\\n1. **Indentation**: Enhanced readability by ensuring consistent 4-space indentation for the if-else block.\\n2. **Spacing Around Operators and Conditionals**: Added spaces around the `<=` operator to make it clearer.\\n3. **Line Breaks**: Placed separate lines for the `return` statements to improve readability.\\n\\nThese changes adhere to the common Python style guide (PEP 8), making the code more readable and maintainable.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Did this Agent work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Looking at the trace output, yes, the agent worked as designed! We can see that:\n",
    "\n",
    "1. The agent received our request with the messy code\n",
    "2. It successfully formatted the code (added proper spacing, indentation, and line breaks)\n",
    "3. It provided a detailed explanation of the changes it made\n",
    "4. All of this was done using our format_code tool\n",
    "\n",
    "However, to be even more thorough, we could:\n",
    "1. Try the `show()` method to see the full conversation history\n",
    "2. Add functionality to run both versions of the code\n",
    "3. Test it with different types of code\n",
    "\n",
    "Would you like to try any of these additional verification steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Agent Configuration\n",
       "\n",
       "**Role**: Python coding assistant  \n",
       "**Model**: gpt-4o  \n",
       "**System**: You are a helpful Python coding assistant. When you see Python code, use the format_code tool to improve its formatting. Explain the formatting changes you make.  \n",
       "**Memory Size**: 10  \n",
       "**Tools**: 1 - format_code\n",
       "\n",
       "## Token Usage\n",
       "CompletionUsage(completion_tokens=334, prompt_tokens=1172, total_tokens=1506, completion_tokens_details=None, prompt_tokens_details=None)\n",
       "\n",
       "## Conversation History\n",
       "**User:** Can you help format this code properly?\n",
       "def fibonacci(n):\n",
       "  if n<=1:return n\n",
       "  else:return fibonacci(n-1)+fibonacci(n-2)\n",
       "\n",
       "**Assistant:** \n",
       "\n",
       "**Tool:** def fibonacci(n):\n",
       "    if n <= 1:\n",
       "        return n\n",
       "    else:\n",
       "        return fibonacci(n - 1) + fibonacci(n - 2)\n",
       "\n",
       "\n",
       "**Assistant:** Here is the properly formatted code:\n",
       "\n",
       "```python\n",
       "def fibonacci(n):\n",
       "    if n <= 1:\n",
       "        return n\n",
       "    else:\n",
       "        return fibonacci(n - 1) + fibonacci(n - 2)\n",
       "```\n",
       "\n",
       "### Changes Made:\n",
       "1. **Indentation**: Enhanced readability by ensuring consistent 4-space indentation for the if-else block.\n",
       "2. **Spacing Around Operators and Conditionals**: Added spaces around the `<=` operator to make it clearer.\n",
       "3. **Line Breaks**: Placed separate lines for the `return` statements to improve readability.\n",
       "\n",
       "These changes adhere to the common Python style guide (PEP 8), making the code more readable and maintainable.\n",
       "\n",
       "**User:** Can you help format this code properly?\n",
       "def fibonacci(n):\n",
       "  if n<=1:return n\n",
       "  else:return fibonacci(n-1)+fibonacci(n-2)\n",
       "\n",
       "**Assistant:** Here is the properly formatted code:\n",
       "\n",
       "```python\n",
       "def fibonacci(n):\n",
       "    if n <= 1:\n",
       "        return n\n",
       "    else:\n",
       "        return fibonacci(n - 1) + fibonacci(n - 2)\n",
       "```\n",
       "\n",
       "### Changes Made:\n",
       "1. **Indentation**: Enhanced readability by ensuring consistent 4-space indentation for the if-else block.\n",
       "2. **Spacing Around Operators and Conditionals**: Added spaces around the `<=` operator to make it clearer.\n",
       "3. **Line Breaks**: Placed separate lines for the `return` statements to improve readability.\n",
       "\n",
       "These changes adhere to the common Python style guide (PEP 8), making the code more readable and maintainable.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_agent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Prompt**\n",
    "\n",
    "Wow. This looks really nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Response**\n",
    "\n",
    "Yes, it does! The `show()` method gives us a great overview of:\n",
    "1. Our agent's configuration (role, model, system prompt)\n",
    "2. The tools it has access to (format_code)\n",
    "3. The complete conversation history\n",
    "4. Token usage statistics\n",
    "\n",
    "Would you like to:\n",
    "1. Add more capabilities to our agent (like code analysis or execution)?\n",
    "2. Try it with a different, more complex piece of code?\n",
    "3. Modify the agent's behavior by changing its system prompt?\n",
    "\n",
    "What interests you most about where we could take this next?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
